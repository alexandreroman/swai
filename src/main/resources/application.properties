spring.application.name=swai
logging.level.com.broadcom.tanzu.demos=DEBUG
logging.level.io.micrometer.registry.otlp=OFF
logging.level.io.opentelemetry.exporter.internal.http=OFF

server.port: ${PORT:8080}

spring.cache.type=redis

spring.ai.openai.chat.options.temperature=0
spring.ai.openai.chat.options.model=gpt-3.5-turbo-1106
spring.ai.openai.chat.options.functions=charactersByFilm,charactersByName,residentsByPlanet,planetsByFilm,planets,films

spring.ai.mistralai.chat.options.temperature=0
spring.ai.mistralai.chat.options.model=mistral-large-latest
spring.ai.mistralai.chat.options.functions=charactersByFilm,charactersByName,residentsByPlanet,planetsByFilm,planets,films

app.swapi.url=https://swapi.dev/api
app.swapi.connectTimeout=10s
app.swapi.readTimeout=10s
app.cache.ttl=10m

management.observations.key-values.application=swai
management.observations.key-values.service=${spring.application.name}
management.observations.key-values.source=${spring.application.name}-${random.uuid}
management.tracing.sampling.probability=1.0
management.otlp.tracing.endpoint=http://localhost:4318/v1/traces
